{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация\n",
    "\n",
    "Сгенерируем точки из трех кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "%pylab inline\n",
    "\n",
    "X = np.zeros((150, 2))\n",
    "\n",
    "np.random.seed(seed=42)\n",
    "X[:50, 0] = np.random.normal(loc=0.0, scale=.3, size=50)\n",
    "X[:50, 1] = np.random.normal(loc=0.0, scale=.3, size=50)\n",
    "\n",
    "X[50:100, 0] = np.random.normal(loc=2.0, scale=.5, size=50)\n",
    "X[50:100, 1] = np.random.normal(loc=-1.0, scale=.2, size=50)\n",
    "\n",
    "X[100:150, 0] = np.random.normal(loc=-1.0, scale=.2, size=50)\n",
    "X[100:150, 1] = np.random.normal(loc=2.0, scale=.5, size=50)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(X[...,0], X[...,1], s=50, cmap='viridis')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=1)\n",
    "kmeans.fit(X)\n",
    "print(kmeans.labels_) #список из номеров кластеров для каждого объекта обучающей выборки\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(X[:,0], X[:,1], c=kmeans.labels_, s=50, cmap='viridis')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим иерархическую кластеризацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "distance_mat = pdist(X) # pdist посчитает нам верхний треугольник матрицы попарных расстояний\n",
    "\n",
    "Z = hierarchy.linkage(distance_mat, 'single') # linkage — реализация агломеративного алгоритма\n",
    "plt.figure(figsize=(10, 5))\n",
    "dn = hierarchy.dendrogram(Z, color_threshold=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что произойдет, если подобрать неверное число кластеров?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15,8))\n",
    "for n_c in range(2,8):\n",
    "    kmeans = KMeans(n_clusters = n_c)\n",
    "    kmeans = kmeans.fit(X)\n",
    "    clusters = kmeans.predict(X)\n",
    "    plt.subplot(2,3,n_c - 1)\n",
    "    plt.scatter(X[:,0], X[:,1], c = clusters)\n",
    "    plt.title('n_clusters = {}'.format(n_c))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "\n",
    "(Density-based spatial clustering of applications with noise)\n",
    "\n",
    "Это алгоритм, основанный на плотности — если дан набор объектов в некотором пространстве, алгоритм группирует вместе объекты, которые расположены близко и помечает как выбросы объекты, которые находятся в областях с малой плотностью (ближайшие соседи которых лежат далеко)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм имеет два основных гиперпараметра:\n",
    "1. `eps` &mdash; радиус рассматриваемой окрестности\n",
    "2. `min_samples` &mdash; число соседей в окрестности\n",
    "\n",
    "Для выполнения кластеризации DBSCAN точки делятся на основные точки, достижимые по плотности точки и выпадающие следующим образом:\n",
    "\n",
    "- Точка $p$ является основной точкой, если по меньшей мере `min_samples` точек находятся на расстоянии, не превосходящем \n",
    "`eps` от неё. Говорят, что эти точки достижимы прямо из $p$.\n",
    "\n",
    "-  Точка $q$ прямо достижима из $p$, если точка $q$ находится на расстоянии, не большем `eps`, от точки $p$, и $p$ — основная точка.\n",
    "Точка $q$ достижима из $p$, если имеется путь \n",
    "$p_1,…,p_n$ где $p_1=p$ и $p_n=q$ , а каждая точка $p_{i+1}$ достижима прямо из $p_i$ (все точки на пути должны быть основными, за исключением $q$).\n",
    "\n",
    "Все точки, не достижимые из основных точек, считаются выбросами.\n",
    "\n",
    "Теперь, если $p$ является основной точкой, то она формирует кластер вместе со всеми точками (основными или неосновными), достижимыми из этой точки. Каждый кластер содержит по меньшей мере одну основную точку. Неосновные точки могут быть частью кластера, но они формируют его «край», поскольку не могут быть использованы для достижения других точек.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим диаграмму, параметр `min_samples`=4.\n",
    "\n",
    "Точка $A$ и другие красные точки являются основными точками, поскольку область с радиусом \n",
    "`eps` , окружающая эти точки, содержит по меньшей мере 4 точки (включая саму точку). Поскольку все они достижимы друг из друга, точки образуют один кластер. Точки $B$ и $C$ основными не являются, но достижимы из $A$ (через другие основные точки), и также принадлежат кластеру. Точка $N$ является точкой шума, она не является ни основной точкой, ни доступной прямо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a href=\"https://commons.wikimedia.org/wiki/File:DBSCAN-Illustration.svg#/media/Файл:DBSCAN-Illustration.svg\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/DBSCAN-Illustration.svg/1200px-DBSCAN-Illustration.svg.png\" alt=\"DBSCAN-Illustration.svg\" width=\"450\" height=\"450\"> </a><br>Автор: <a href=\"//commons.wikimedia.org/wiki/User:Chire\" title=\"User:Chire\">Chire</a> &mdash; <span class=\"int-own-work\" lang=\"ru\">собственная работа</span>, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\" title=\"Creative Commons Attribution-Share Alike 3.0\">CC BY-SA 3.0</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результаты кластеризации при разном выборе параметров `eps` и `min_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "plt.figure(figsize= (15,23))\n",
    "i = 1\n",
    "for samples in [2, 4, 8]:\n",
    "    for e in [0.1, 0.2, 0.5, 1, 2]:\n",
    "        dbscan = DBSCAN(eps=e, min_samples=samples)\n",
    "        clusters = dbscan.fit_predict(X)\n",
    "        plt.subplot(6, 3, i)\n",
    "        plt.scatter(X[:,0], X[:,1], c = clusters)\n",
    "        plt.title('eps = {}, min_samples = {}'.format(e, samples))\n",
    "        i += 1\n",
    "    i+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Визуализация работы DBSCAN](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример: кластеризация игроков NBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nba = pd.read_csv(\"nba_2019.csv\")\n",
    "nba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим kmeans с 5ю кластерами только к числовым столбцам (объявим алгоритм и обучим его с помощью метода fit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "numeric_cols = nba._get_numeric_data().dropna(axis=1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=3)\n",
    "kmeans.fit(numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем данные с помощью метода главных компонент с n_components = 2:\n",
    "\n",
    "    1) Применим метод главных компонент\n",
    "    \n",
    "    2) Нарисуем полученные точки на плоскости, раскрашенные в цвета, соответствующие кластерам (см. пример выше)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "res = pca.fit_transform(numeric_cols)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(res[:,0], res[:,1], c=kmeans.labels_, s=50, cmap='viridis')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какое смысловое значение несут кластеры.\n",
    "\n",
    "1) Визуализируем точки в осях nba['pts'] (total points) и nba['ast'] (total assistances) и раскрасим их в цвета кластеров.\n",
    "\n",
    "2) Визуализируем точки в осях nba['age'] (age) и nba['mp'] (minutes played) и раскрасим их в цвета кластеров.\n",
    "\n",
    "Подпишем оси."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(nba['PTS'], nba['AST'], c=kmeans.labels_, s=50, cmap='viridis')\n",
    "plt.xlabel('points')\n",
    "plt.ylabel('assistances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(nba['Age'], nba['MP'], c=kmeans.labels_, s=50, cmap='viridis')\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('minutes played')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализация центроидов\n",
    "\n",
    "Метод `sklearn.KMeans` содержит параметры `n_init` (число запусков из различных начальных приближений) и `init`. Есть три способа инициализации центроидов:\n",
    "- `k-means++` – \"умная\" инициализация центроидов для ускорения сходимости.\n",
    "- `random` – случайная инициализация центроидов.\n",
    "- `ndarray` – заданная инициализация центроидов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сжатие изображений с K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('cat.jpg')[..., 1]\n",
    "plt.figure(figsize = (15, 9))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from scipy.stats import randint\n",
    "\n",
    "X = img.reshape((-1, 1)) #вытягиваем картинку в вектор\n",
    "k_means = MiniBatchKMeans(n_clusters=10)\n",
    "k_means.fit(X) \n",
    "values = k_means.cluster_centers_\n",
    "labels = k_means.labels_\n",
    "\n",
    "img_compressed = values[labels].reshape(img.shape) #возвращаем к размерности исходной картинки\n",
    "\n",
    "plt.figure(figsize = (15, 9))\n",
    "plt.axis('off')\n",
    "plt.imshow(img_compressed, cmap = 'gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмите любую фотографию (можно работать с той же) и подберите минимальное число кластеров, которое визуально не ухудшает качество изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нахождение тем в текстах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Применим KMeans для кластеризации текстов из 4 новостных категорий.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "\n",
    "categories = [\n",
    "    'talk.politics.misc',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space']\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories,\n",
    "                             shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"{len(dataset.data)} documents\")\n",
    "print(f\"{len(dataset.target_names)} categories\")\n",
    "\n",
    "labels = dataset.target\n",
    "true_k = np.unique(labels).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Закодируем тексты с помощью TF-IDF признаков.**\n",
    "\n",
    "![How](tf-idf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting features from the training dataset using a sparse vectorizer\")\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=1000,\n",
    "                             min_df=2, stop_words='english')\n",
    "\n",
    "X = vectorizer.fit_transform(dataset.data)\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**И применим к получившимся векторам метод $k$ средних и выведем метрики качества кластеризации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X)\n",
    "\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\"Adjusted mutual info score: %.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels, km.labels_))\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выведем слова, соответствующие самым весомым компонентам центров кластеров.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names_out()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % (i + 1), end='')\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind], end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кластеризация рукописных цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X, y = digits.data, digits.target\n",
    "Im = digits.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем на экран первые 20 цифр (в цветовой схеме 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(Im[i], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим kmeans с десятью кластерами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=10, init='k-means++', max_iter=100, n_init=1)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем на экран метрики качества кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = digits.target\n",
    "\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\"Adjusted mutual info score: %.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels, km.labels_))\n",
    "\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуем центры получившихся кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(2, 5)\n",
    "for ax, center in zip(axes.ravel(), km.cluster_centers_):\n",
    "    ax.matshow(center.reshape(8, 8), cmap=plt.cm.gray)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация получилась довольно качественной. Визуализируем наши объекты (изображения цифр) как точки на двумерной плоскости.\n",
    "\n",
    "Визуализируем данные с помощью PCA с двумя компонентами:\n",
    "\n",
    "1) объявим модель и обучим её (fit_transform)\n",
    "\n",
    "2) нарисуем результат, покрасив точки в цвета, соответствующие кластерам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "print('Projecting %d-dimensional data to 2D' % X.shape[1])\n",
    "\n",
    "plt.scatter(X_reduced[:,0], X_reduced[:,1], c=km.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем данные с помощью t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(random_state=17)\n",
    "X_tsne = tsne.fit_transform(X) # две координаты\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, \n",
    "            edgecolor='none', alpha=0.7, s=40,\n",
    "            cmap=plt.cm.get_cmap('nipy_spectral', 10))\n",
    "plt.colorbar()\n",
    "plt.title('MNIST. t-SNE projection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки\n",
    "- <a href=\"https://en.wikipedia.org/wiki/K-means_clustering\">k-means</a> на Википедии\n",
    "- <a href=\"https://scikit-learn.org/stable/modules/clustering.html\">обзор</a> методов кластеризации в sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "name": "lesson8_part1_kmeans.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
