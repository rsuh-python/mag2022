{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b4084a-5599-4435-8ebd-9eb077ba934a",
   "metadata": {},
   "source": [
    "Посмотрим процедуру создания Dataset в торче на очень простом примере. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500a7ff-739c-4cbe-a14f-da072b09707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8caee8f-51fb-42dd-ae9f-3b5ab9637ca5",
   "metadata": {},
   "source": [
    "Датасет должен уметь возвращать свою длину и пары фичи - ytrue. Поэтому перегрузим три метода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b256d43a-d858-43a0-86c0-331627175ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, txt, labels):\n",
    "        self.labels = labels\n",
    "        self.text = text\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        text = self.text[idx]\n",
    "        sample = {\"Text\": text, \"Class\": label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6965aca-438e-4e35-a31c-b7db506c7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем игрушечный датасетик\n",
    "text = ['Happy', 'Amazing', 'Sad', 'Unhappy', 'Glum']\n",
    "labels = ['Positive', 'Positive', 'Negative', 'Negative', 'Negative']\n",
    "# соберем из него датафрейм\n",
    "text_labels_df = pd.DataFrame({'Text': text, 'Labels': labels})\n",
    "# и передадим в класс Dataset\n",
    "TD = CustomTextDataset(text_labels_df['Text'], text_labels_df['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32cea27-b5cc-4d70-b8f1-b13341695a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Посмотрим, как он будет работать\n",
    "print('\\nFirst iteration of data set: ', next(iter(TD)), '\\n')\n",
    "print('Length of data set: ', len(TD), '\\n')\n",
    "print('Entire data set: ', list(DataLoader(TD)), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3942d4ae-fb79-4b16-8337-7d728915fa8d",
   "metadata": {},
   "source": [
    "Иногда нам еще бывает нужна специальная функция для предобработки батча перед тем, как его передавать в модель. Ее можно имплементировать в классе датасета или просто написать отдельно. Она передается в параметрах DataLoader. Мы напишем тоже игрушечную функцию, которая ничего особенного делать не будет, сымитирует превращение текстов в тензора. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb513c49-3285-4df4-bdda-d95c261d1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):    \n",
    "    word_tensor = torch.tensor([[1.], [0.], [45.]])\n",
    "    label_tensor = torch.tensor([[1.]])\n",
    "    \n",
    "    text_list, classes = [], []    \n",
    "    for (_text, _class) in batch:\n",
    "        text_list.append(word_tensor)\n",
    "        classes.append(label_tensor)     \n",
    "        text = torch.cat(text_list)\n",
    "        classes = torch.tensor(classes)     \n",
    "        return text, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2ec77-10dc-4d8f-a351-c2f58b2defe6",
   "metadata": {},
   "source": [
    "Посмотрим, как это будет работать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbbfda8-2f5f-44be-b3c3-6da34d14dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_DS = DataLoader(TD, batch_size=2, shuffle=True)\n",
    "for (idx, batch) in enumerate(DL_DS):    \n",
    "    print(idx, 'Text data: ', batch['Text'])    \n",
    "    print(idx, 'Class data: ', batch['Class'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b060878-1b8f-487a-a4e1-ea1ff5bc1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_DS = DataLoader(TD, batch_size=2, collate_fn=collate_batch)\n",
    "for (idx, batch) in enumerate(DL_DS): \n",
    "    print(f'{idx}.\\nFeatures: {batch[0]}\\nY: {batch[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb25e0-ccdc-478e-b27c-eb86bee03f6d",
   "metadata": {},
   "source": [
    "Посмотрим функцию collate_fn подробнее. \n",
    "\n",
    "collate_fn получает список кортежей (если \\_\\_getitem\\_\\_ в датасете их возвращает) или просто обычный список чего угодно. Основная задача этой функции - собрать батч, не тратя время на соображения, как там наши данные поделить и еще пошаффлить. У DataLoader есть встроенная функция collate_fn, которая используется, если мы не передали кастомной. \n",
    "\n",
    "Допустим, у нас есть другой игрушечный датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb6d90-12b6-49ac-acec-e9e37832a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [0.1, 7.4, 0],\n",
    "    [-0.2, 5.3, 0],\n",
    "    [0.2, 8.2, 1],\n",
    "    [0.2, 7.7, 1]])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41a4e9-6ab6-4eb3-b72c-76ce6674d4d9",
   "metadata": {},
   "source": [
    "На самом деле мы можем его прямиком сунуть в DataLoader, он сам разберется:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12463373-3916-4108-8601-2c786418a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data, batch_size=2, shuffle=False)\n",
    "batch = next(iter(loader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06eaa8e-7242-47fc-9950-962c85fe044c",
   "metadata": {},
   "source": [
    "DataLoader не нашел игреки, правда, но догадался разделить по объектам. Умеет он это делать и со словарями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730700bd-c83f-4f4c-9ceb-7b3d2967304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# теперь датасет - список словарей\n",
    "dict_data = [\n",
    "    {'x1': 0.1, 'x2': 7.4, 'y': 0},\n",
    "    {'x1': -0.2, 'x2': 5.3, 'y': 0},\n",
    "    {'x1': 0.2, 'x2': 8.2, 'y': 1},\n",
    "    {'x1': 0.2, 'x2': 7.7, 'y': 10},\n",
    "]\n",
    "pprint(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb960ca-a707-4327-95db-e8eff2436ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dict_data, batch_size=2, shuffle=False)\n",
    "batch = next(iter(loader))\n",
    "pprint(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65591d9-b67a-497e-9ac0-f6d8c371e035",
   "metadata": {},
   "source": [
    "Проблемки у дефолтного collate_fn обычно начинаются, если наши данные - разных размеров. Когда это может быть? Когда мы работаем с текстами: например, каждый объект - это предложение, а все предложения, как мы знаем, разной длины. Торч с батчами разной длины работать не умеет. Такой код вызовет ошибку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc147a-d639-4d38-9c3f-36989626eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_data = [\n",
    "    {'tokenized_input': [1, 4, 5, 9, 3, 2],\n",
    "     'label':0},\n",
    "    {'tokenized_input': [1, 7, 3, 14, 48, 7, 23, 154, 2],\n",
    "     'label':0},\n",
    "    {'tokenized_input': [1, 30, 67, 117, 21, 15, 2],\n",
    "     'label':1},\n",
    "    {'tokenized_input': [1, 17, 2],\n",
    "     'label':0},\n",
    "]\n",
    "loader = DataLoader(nlp_data, batch_size=2, shuffle=False)\n",
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977a1042-079d-4008-a528-264485427e30",
   "metadata": {},
   "source": [
    "Что делать? Приходится добивать предложения т.н. паддингами (говорят - паддить). Тут есть несколько стратегий, одна из которых предполагает, что мы берем несколько предложений в батч, выбираем самое длинное из них, а остальные добиваем специальными штуками до длины самого длинного; другая предполагает, что мы выбираем среднюю длину по батчу и обрезаем слишком длинные, а слишком короткие добиваем. Причем можно либо весь датасет западдить по самому длинному предложению, либо паддить каждый батч на лету (обычно делается последнее). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e1b15-e0e0-47c8-ad5a-440e5cbf213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence # торч будет все делать за нас\n",
    "\n",
    "def custom_collate(data): \n",
    "    # отделим игреки от фич\n",
    "    inputs = [torch.tensor(d['tokenized_input']) for d in data] \n",
    "    labels = [d['label'] for d in data] \n",
    "\n",
    "    inputs = pad_sequence(inputs, batch_first=True) \n",
    "    labels = torch.tensor(labels) \n",
    "\n",
    "    return { \n",
    "        'tokenized_input': inputs,\n",
    "        'label': labels\n",
    "    }\n",
    "\n",
    "loader = DataLoader(nlp_data, batch_size=2, shuffle=False, collate_fn=custom_collate) \n",
    "\n",
    "iter_loader = iter(loader)\n",
    "batch1 = next(iter_loader)\n",
    "pprint(batch1)\n",
    "batch2 = next(iter_loader)\n",
    "pprint(batch2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636be88b-95d4-4e24-a663-cae052b732cc",
   "metadata": {},
   "source": [
    "Что же это за batch_first такой? Дело в том, как работает pad_sequence. Она принимает на вход объект размеров $L \\times *$ (L - длина списка, * - остальные размерности) и возвращает новый объект размерности $T \\times B \\times *$, где Т - длина самой длинной последовательности, B - длина батча. То есть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf923b24-f21e-41a3-bbdc-a72700958343",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(8, 1) # условное предложение из 8 слов\n",
    "print('Так выглядит самая длинная последовательность:', a)\n",
    "b = torch.ones(5, 1)\n",
    "c = torch.ones(3, 1)\n",
    "batch = [a, b, c]\n",
    "print(f'Длина нашего батча: {len(batch)}')\n",
    "print(pad_sequence(batch).size())\n",
    "print(pad_sequence(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d81970-86e9-4463-b36e-7c59fed66714",
   "metadata": {},
   "source": [
    "Получается, pad_sequence все напутал и мы вместо батча из трех предложений получаем неведомо что из 8 неведомо чего. Параметр batch_first приходит на помощь и, собственно, говорит pad_sequence, что нужно поменять размерность местами и первым возвращать размерность батча. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ac04a-e531-492f-905b-1995569ea41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(8, 1) # условное предложение из 8 слов\n",
    "print('Так выглядит самая длинная последовательность:', a)\n",
    "b = torch.ones(5, 1)\n",
    "c = torch.ones(3, 1)\n",
    "batch = [a, b, c]\n",
    "print(f'Длина нашего батча: {len(batch)}')\n",
    "print(pad_sequence(batch, batch_first=True).size())\n",
    "print(pad_sequence(batch, batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc6046-6267-4845-8f39-70fd57bfa7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
