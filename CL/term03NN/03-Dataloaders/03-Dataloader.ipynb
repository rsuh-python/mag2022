{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d15bce-e0f8-4bde-82c8-ac9abfb7b497",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2333acd-699e-46a3-82e4-3cc7fe4463f3",
   "metadata": {},
   "source": [
    "Датасет хранит все данные, а даталоудер может по ним итерироваться, управлять созданием батчей, трансформировать данные и т.д. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69b722c-5fa9-4552-bd6c-af3f256daeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9b718-f1aa-40ea-864d-65d8812727fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from torchmetrics import Accuracy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dfbc3a-dc4b-42e5-ad5c-2ae05f3d46e4",
   "metadata": {},
   "source": [
    "Pandas для нас необязателен, но его удобно использовать. \n",
    "\n",
    "У нас есть датасет из прошлого семестра про качество вина. Подгрузим его. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc30c416-4fd3-48d0-b862-91aed3703fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/rsuh-python/mag2022/main/CL/term02/04-ClassificationTrees/winequalityN.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed55ce-78d1-496b-bb87-672e2186f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequalityN.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38298019-6ce2-4124-8cc4-7fc285d7d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8572897f-48c7-4157-9081-4bcfd9fd90f8",
   "metadata": {},
   "source": [
    "В датасете есть пропуски: дропнем их, иначе торчу будет плохо. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfbe884-5a54-4e6c-87de-a677b8c106fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725fd2a-fc82-48c1-ae4c-8ac77182e7e5",
   "metadata": {},
   "source": [
    "Для простоты сейчас оставим только числовые данные. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e68ab2-89d2-435b-8b2f-1996164b15ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb037104-44a5-46d9-8223-6b6b486dce36",
   "metadata": {},
   "source": [
    "Допустим, мы хотим обучить простенькую нейронку на этих данных. Посмотрим распределение классов и их количество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c82bd8-68da-480f-96b9-fc0a7ed25b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.quality.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414c3baf-ff75-44db-93c1-822235eef3d0",
   "metadata": {},
   "source": [
    "Давайте укрупним классы: сольем 3, 4 с 5 и 8, 9 с 7 (это, конечно, не дело, но нам пока побаловаться сойдет). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed1040b-7d4e-42dd-9627-d04a3c92a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['quality'] == 8, 'quality'] = 7\n",
    "data.loc[data['quality'] == 9, 'quality'] = 7\n",
    "data.loc[data['quality'] == 3, 'quality'] = 5\n",
    "data.loc[data['quality'] == 4, 'quality'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b5e84-c748-4ff0-ab4d-1ba1dd8cb82d",
   "metadata": {},
   "source": [
    "Отделим мухи от котлет, нормализуем данные и для красоты перекодируем классы в 0, 1, 2 (хотя в целом пофиг вроде бы). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34ba70-959e-4f50-87a0-1221c8831fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('quality', axis=1)\n",
    "y = data.quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d185f-caba-47aa-a535-876ebbf87659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a37c1b-e93d-46ee-8501-6a748ec9c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8824378-af06-4681-9c46-3783a51854c2",
   "metadata": {},
   "source": [
    "Для таких простых табличных данных можно использовать стандартные Dataset & DataLoader, но мы посмотрим, как можно написать собственный класс Dataset. \n",
    "\n",
    "Поделим на трейн и тест обычным sklearn'ом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100aaefa-8b97-4a17-b2cf-aeafdab5a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e824b7c5-69fd-4a22-8053-9c05563390f2",
   "metadata": {},
   "source": [
    "В классе для датасета необходимо перегрузить два метода (помимо init): чтобы экземпляр возвращал свою длину и выдавал пару фичи - ytrue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171421ef-1073-40de-994f-f7b45a9b41a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155534fd-3ece-48a2-834f-7dfdf7436720",
   "metadata": {},
   "source": [
    "Проверим, как это будет выглядеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91628de6-a7e6-407d-8999-afc57a78507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DataLoader(dataset=MyDataset(X_train, y_train), batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3488da8-b905-4d3c-b4ad-a5b226c0a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7507b9e7-5b71-4b44-b503-8647e850dc22",
   "metadata": {},
   "source": [
    "Теперь можно собрать трейн и тест. На трейне хотим шаффлить, чтобы было как можно больше вариаций в батчах, а на тесте скорее нет - для детерминированности результата. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e7b1d-3d63-442a-9658-1720630a1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=MyDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=MyDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae2af38-cdbb-42e4-8c00-e9bb260270cb",
   "metadata": {},
   "source": [
    "Зададим параметры и напишем класс с моделью. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec0e874-78a6-42a8-87bc-4bd04284c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 11\n",
    "HIDDEN_SIZE = 35\n",
    "OUTPUT_SIZE = 3\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 1024 # у нас очень маленький датасет с маленьким набором фич, можем хоть весь целиком в батч запихнуть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a6644c-9b8f-4630-a000-e74d91b34005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=INPUT_SIZE, out_features=HIDDEN_SIZE)\n",
    "        self.fc2 = nn.Linear(in_features=HIDDEN_SIZE, out_features=HIDDEN_SIZE)\n",
    "        self.out = nn.Linear(in_features=HIDDEN_SIZE, out_features=OUTPUT_SIZE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.LeakyReLU()(self.fc1(x)) # побалуемся с функциями активации\n",
    "        x = nn.LeakyReLU()(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446d97a-3942-43da-9a8c-f46b13d59bc9",
   "metadata": {},
   "source": [
    "Соберем нужные штуки и инициализируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7eebcf-9bf8-4c69-a61e-85396b792dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "accuracy = Accuracy(task='multiclass', num_classes=3)\n",
    "\n",
    "set_random_seed(42)\n",
    "model = TorchModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927bc348-42ff-4a38-ba5b-94bddff6dd70",
   "metadata": {},
   "source": [
    "Скопипастим из прошлых тетрадок трейнлуп..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75cf271-2075-4387-a753-934bf18e6308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loss_values = []\n",
    "train_accuracy_values = []\n",
    "valid_loss_values = []\n",
    "valid_accuracy = []\n",
    "\n",
    "def run_train():\n",
    "    step = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "        for features, label in train_loader:\n",
    "            # Reset gradients\n",
    "\n",
    "            output = model(features)\n",
    "            # Calculate error and backpropagate\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            acc = accuracy(output, label).item()\n",
    "\n",
    "            # Update weights with gradients\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(acc)\n",
    "\n",
    "        train_loss_values.append(np.mean(running_loss))\n",
    "        train_accuracy_values.append(np.mean(running_acc))\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'EPOCH {epoch}: train_loss: {train_loss_values[-1]}')# train_accuracy_values[-1]))\n",
    "\n",
    "\n",
    "        # Run validation\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "        for features, label in test_loader:\n",
    "            output = model(features)\n",
    "            # Calculate error and backpropagate\n",
    "            loss = criterion(output, label)\n",
    "            acc = accuracy(output, label).item()\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(acc)\n",
    "\n",
    "        valid_loss_values.append(np.mean(running_loss))\n",
    "        valid_accuracy.append(np.mean(running_acc))\n",
    "        if epoch % 20 == 0:\n",
    "            print(f'EPOCH {epoch}: valid_loss: {valid_loss_values[-1]}, valid_accuracy: {valid_accuracy[-1]}')\n",
    "        \n",
    "    return train_loss_values, train_accuracy_values, valid_loss_values, valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4c2c2-dbed-40af-b76f-9d01dfab0d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_values, train_accuracy_values, valid_loss_values, valid_accuracy = run_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
