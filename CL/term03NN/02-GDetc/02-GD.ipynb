{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1trn9F4vHX9"
   },
   "source": [
    "# Классификация и градиентные спуски\n",
    "\n",
    "В этой тетрадке мы попробуем немного посмотреть на то, как работают разные градиентные спуски. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcgDcJOovHYB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings       \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DZpKIQpSEhT4",
    "outputId": "e033c25c-58e2-4efd-b8c2-cd40d373c230"
   },
   "outputs": [],
   "source": [
    "# FOR GOOGLE COLAB TO GET DATA\n",
    "# !git clone https://github.com/rsuh-python/mag2022.git\n",
    "# %cd /content/mag2022/CL/term03NN/02-GDetc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIsyhmUjvHYC"
   },
   "source": [
    "# 1. Выборка\n",
    "\n",
    "Делать всё это мы будем на животных. Ежегодно около 7.6 миллионов бедных животных в США оказываются в приютах. Часть из них находит себе новую семью, часть возвращается к старому (бывает, что питомец потерялся и его нашли на улице), а часть погибает. Ужегодно усыпляется около 2.7 млн. собак и кошек.  \n",
    "\n",
    "Используя датасет с входной информацией (цвет, пол, возраст и т.п.) из одного из приютов, мы попытаемся спрогнозировать что произойдёт с новыми животными, которые попадут в этот приют. Данные, используемые в тетрадке уже были предварительно обработаны и приведены в удобную для построения моделей форму. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "VnAi3Sdo6JzK",
    "outputId": "b44487a0-247f-49e9-ebec-fcdd9b5f877c"
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('./data/X_cat.csv', sep = '\\t', index_col=0)\n",
    "target = pd.read_csv('./data/y_cat.csv', sep = '\\t', index_col=0, names=['status'])\n",
    "\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5ZSefafvHYE"
   },
   "source": [
    "В датасете находится около 27 тысяч наблюдений и 39 регрессоров. Посмотрим на то как выглядит распределение того, что произошло со зверятами по особям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8IptC3WKvHYF",
    "outputId": "b9fbd72f-73dd-408e-a58f-2d6db99509fd"
   },
   "outputs": [],
   "source": [
    "target.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9bQ0IkjvHYF"
   },
   "source": [
    "Видим, что классы несбалансированы. Попробуем оставит четыре класса и объединить класс умерших животных с классом животных, которых усыпили. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21PcHtlSvHYG"
   },
   "outputs": [],
   "source": [
    "target = target.values\n",
    "target[target == 'Died'] = 'Euthanasia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeP0Lhe2vHYG"
   },
   "source": [
    "Закодируем классы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6oWokBTsvHYG",
    "outputId": "ba3300fb-c064-4802-bc86-e0ea86bd308a"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(target)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmfsvLULvHYH",
    "outputId": "172815ee-cfe3-4122-8531-d11e5e4ca930"
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otLvFCPavHYI",
    "outputId": "716b1647-2d60-4124-cbfc-ae493994f271"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0TQR8_evHYI"
   },
   "source": [
    "Разобьём выборку на тренировочную и тестовую. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDNHmr36vHYI",
    "outputId": "db280f88-c1c9-4d78-f954-7f48b086043d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = y, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9IYETYPvHYJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UGwCG70vHYJ"
   },
   "source": [
    "# 2. Архитектурка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZTyzK4Py50b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn            # содержит функции для реалзации архитектуры нейронных сетей\n",
    "import torch.nn.functional as F  # содержит различные функции активации и не только\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezoTBX73vHYK"
   },
   "source": [
    "Функция для рисования графиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SXl9eDVvHYK"
   },
   "outputs": [],
   "source": [
    "def plot(histories):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    \n",
    "    for name, val_loss in histories:\n",
    "        plt.plot(val_loss, label=name)\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DDTRshI22Ho"
   },
   "source": [
    " Соберем архитектуру модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vV4QLIVv0r0_"
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 37\n",
    "HIDDEN_SIZE = 25\n",
    "OUTPUT_SIZE = 4\n",
    "BATCH_SIZE = 1000\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"тут мы просто объявляем, какие нам нужны слои, \n",
    "        и сохраняем их в динамических атрибутах\"\"\"\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=INPUT_SIZE, out_features=HIDDEN_SIZE)\n",
    "        self.fc2 = nn.Linear(in_features=HIDDEN_SIZE, out_features=HIDDEN_SIZE)\n",
    "        self.out = nn.Linear(in_features=HIDDEN_SIZE, out_features=OUTPUT_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Этот метод будет вызываться невидимо для нас, \n",
    "        когда мы передаем в модель данные (подумаем про __call__...)\"\"\"\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = nn.Softmax()(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7nzgau33Avb"
   },
   "source": [
    "Напишем функцию, которая будет тренировать нейронную сеть. Функция имеет 2 логические части: первая - тренировочная, вторая - валидационная, другими словами, та, на которой вычисляется ошибка и сравнивается с ошибкой на тренировочных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRn2R0KJ1Kmp"
   },
   "outputs": [],
   "source": [
    "def run_train(model, optimizer, criterion, scheduler=None):\n",
    "    train_loss_values = []\n",
    "    train_accuracy_values = []\n",
    "    valid_loss_values = []\n",
    "    valid_accuracy = []\n",
    "    lr_history = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "        for features, label in train_loader:\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # run model on the chosen batch\n",
    "            output = model(features)\n",
    "\n",
    "            # Calculate error and backpropagate\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "\n",
    "            # manual accuracy calculation; no torch lightning\n",
    "            acc = (output.argmax(dim=1)==label).sum() / len(label)\n",
    "\n",
    "            # Update weights with gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(acc)\n",
    "\n",
    "\n",
    "        train_loss_values.append(np.mean(running_loss))\n",
    "        train_accuracy_values.append(np.mean(running_acc))\n",
    "        if epoch % 20 == 0:\n",
    "            print('EPOCH %d,  train_loss: %f, valid_accuracy: %f' % (epoch, train_loss_values[-1], train_accuracy_values[-1]))\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        # Run validation\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "        with torch.no_grad(): # in validation loop we do not need gradients calculation; so switch it off\n",
    "            for features, label in test_loader:\n",
    "                output = model(features)\n",
    "                \n",
    "                # Calculate error ana accuracy\n",
    "                loss = criterion(output, label)\n",
    "                acc = (output.argmax(dim=1)==label).sum() / len(label)\n",
    "\n",
    "                running_loss.append(loss.item())\n",
    "                running_acc.append(acc)\n",
    "\n",
    "            valid_loss_values.append(np.mean(running_loss))\n",
    "            valid_accuracy.append(np.mean(running_acc))\n",
    "            if epoch % 20 == 0:\n",
    "                print('EPOCH %d, valid_loss: %f, valid_accuracy: %f' % (epoch, valid_loss_values[-1], valid_accuracy[-1]))\n",
    "\n",
    "        if scheduler is not None:\n",
    "            # Decay Learning Rate\n",
    "            scheduler.step()\n",
    "            lr_history.append(scheduler.get_last_lr())\n",
    "\n",
    "    if scheduler is not None:\n",
    "        return train_loss_values, train_accuracy_values, valid_loss_values, valid_accuracy, lr_history\n",
    "        \n",
    "    return train_loss_values, train_accuracy_values, valid_loss_values, valid_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6q27i0kP3a0g"
   },
   "source": [
    "Создадим PyTorch `Dataloader`. Объект DataLoader принимает на вход датасет и ряд параметров, задающих процедуру формирования батча данных.\n",
    "\n",
    "Основным входным параметром `Dataloader` является объект PyTorch `Dataset`. Он нужен для доступа к элементы данных по конкретному индексу. \n",
    "\n",
    "На первый взгляд такая конструкция может показаться странной и излишней. Однако к ней просто нужно привыкнуть и со временем станет понятно насколько она удобна и лаконична. В силу своей гибкости она позволяет формировать размер и структуру батча по желанию, а также собирать батч из заранее выбранных элементов данных. Такая кастомная сборка батча может пригодиться, например, при работе с последовательными данными, такими как предложения в тексте, имеющими разную длину. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpRy2C4V3a_B"
   },
   "outputs": [],
   "source": [
    "def create_data_loader(X_train, y_train, X_test, y_test):\n",
    "    train_tensor = data_utils.TensorDataset(torch.tensor(X_train.astype(np.float32)), torch.tensor(y_train))\n",
    "    train_loader = data_utils.DataLoader(dataset=train_tensor,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True)\n",
    "\n",
    "    test_tensor = data_utils.TensorDataset(torch.tensor(X_test.astype(np.float32)), torch.tensor(y_test))\n",
    "    test_loader = data_utils.DataLoader(dataset=test_tensor,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = create_data_loader(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Py6-_0wpvHYN"
   },
   "source": [
    "# 3. Оптимизация \n",
    "\n",
    "### SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGFgUTyuvHYO",
    "outputId": "bb05557b-fdfe-434a-b8e2-1c782be3de08"
   },
   "outputs": [],
   "source": [
    "# Первая простенькая моделька \n",
    "model1 = MyModel()\n",
    "\n",
    "# инициализируем SGD optimizer\n",
    "sgd = optim.SGD(model1.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# инициализируем Loss function (функцию потерь)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# запускаем процесс обучения\n",
    "train_loss_values, train_accuracy_values, valid_loss_values, valid_accuracy = run_train(model1, optimizer=sgd, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "Hp3ghesy9JWb",
    "outputId": "9e689567-22cc-43df-a99f-c257eabe5bf0"
   },
   "outputs": [],
   "source": [
    "plot([('Simple SGD', valid_loss_values)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_5OGJF4vHYP"
   },
   "source": [
    "### Nesterov Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QVwA2M_pvHYP",
    "outputId": "b368bfd0-7d75-46aa-ff96-72d4a4b2669c"
   },
   "outputs": [],
   "source": [
    "# Первая простенькая моделька \n",
    "model2 = MyModel()\n",
    "\n",
    "# инициализируем SGD optimizer\n",
    "sgd = optim.SGD(model2.parameters(), lr=LEARNING_RATE, momentum=0.9, nesterov=True)\n",
    "\n",
    "# запускаем процесс обучения\n",
    "train_loss_values2, train_accuracy_values2, valid_loss_values2, valid_accuracy2 = run_train(model2, optimizer=sgd, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "AA5eiW_--AN5",
    "outputId": "755a6bb1-131c-43bd-d198-e1e0edb08409"
   },
   "outputs": [],
   "source": [
    "plot([('Simple SGD', valid_loss_values), \n",
    "      ('momentum nesterov SGD', valid_loss_values2)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcfJX5jPvHYQ"
   },
   "source": [
    "### RMSprop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ud8z7qOSvHYQ",
    "outputId": "ff8299a2-0af0-41f5-bda8-437369585899"
   },
   "outputs": [],
   "source": [
    "# Первая простенькая моделька \n",
    "model3 = MyModel()\n",
    "\n",
    "# инициализируем SGD optimizer\n",
    "rmsprop = optim.RMSprop(model3.parameters(), lr=LEARNING_RATE, alpha=0.9, eps=1e-08)\n",
    "\n",
    "# запускаем процесс обучения\n",
    "train_loss_values3, train_accuracy_values3, valid_loss_values3, valid_accuracy3 = run_train(model3, optimizer=rmsprop, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "8FjU0em9_X2g",
    "outputId": "696e04fa-6f0c-4e03-d400-2a26dbb84cfd"
   },
   "outputs": [],
   "source": [
    "plot([('Simple SGD', valid_loss_values), \n",
    "      ('momentum nesterov SGD', valid_loss_values2),\n",
    "      ('RMSprop', valid_loss_values3)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZetN13i5vHYS"
   },
   "source": [
    "### Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxjzA6G5vHYT",
    "outputId": "2c22dd5d-ef50-4b79-89c6-a903d16de89d"
   },
   "outputs": [],
   "source": [
    "# Первая простенькая моделька \n",
    "model4 = MyModel()\n",
    "\n",
    "# инициализируем SGD optimizer\n",
    "adam = optim.Adam(model4.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "# запускаем процесс обучения\n",
    "train_loss_values4, train_accuracy_values4, valid_loss_values4, valid_accuracy4 = run_train(model4, optimizer=adam, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "VmhZJRiSAKDd",
    "outputId": "efa49c0b-38d9-43b0-da0f-a5063ea6191b"
   },
   "outputs": [],
   "source": [
    "plot([('Simple SGD', valid_loss_values), \n",
    "      ('momentum nesterov SGD', valid_loss_values2),\n",
    "      ('RMSprop', valid_loss_values3),\n",
    "      ('ADAM', valid_loss_values4)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsIQGhJyvHYV"
   },
   "source": [
    "# 4. Стратегии с постепенным понижением lr \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZLkoUa6EQ_n"
   },
   "outputs": [],
   "source": [
    "# функция для картинок, чтобы видеть как скорость обучения меняется от эпохи к эпохе\n",
    "def plot_learning_rate(lr_history):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(range(1, EPOCHS+1), lr_history, label='learning rate')\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.xlim([1, epochs+1])\n",
    "    plt.ylabel(\"learning rate\")\n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Learning rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DORJkuW4vHYW"
   },
   "source": [
    "Стартовую скорость обучения специально берём большой! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coV4-vvjvHYW"
   },
   "outputs": [],
   "source": [
    "INIT_LR = 0.1  # устанавливаем lr намеренно большим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPcjsNn2IOaE",
    "outputId": "dd618ed7-dff2-4971-a1a6-bdd005cc794a"
   },
   "outputs": [],
   "source": [
    "adam = optim.SGD(model5.parameters(), lr=INIT_LR)\n",
    "scheduler = StepLR(adam, step_size=2, gamma=0.1)\n",
    "\n",
    "for i in range(10):\n",
    "    print(i+1, scheduler.get_last_lr())\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZG_eCMmHroe",
    "outputId": "248d75a1-7c29-4aec-db35-9a28dafb7aed"
   },
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-l0AcAMOvHYX",
    "outputId": "b8c11252-2ccd-4644-b143-50431b52e0f7"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "# Первая простенькая моделька \n",
    "model5 = MyModel()\n",
    "\n",
    "# инициализируем SGD optimizer\n",
    "adam = optim.Adam(model5.parameters(), lr=INIT_LR, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "# инициализируем \n",
    "scheduler = StepLR(adam, step_size=50, gamma=0.5)\n",
    "\n",
    "# запускаем процесс обучения\n",
    "train_loss_values5, train_accuracy_values5, valid_loss_values5, valid_accuracy5, lr_history5 = run_train(model5, optimizer=adam, \n",
    "                                                                                                        criterion=criterion, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "uvz8awtXvHYX",
    "outputId": "4ff84c37-7a4e-4ae5-b312-9612abe7b2e7"
   },
   "outputs": [],
   "source": [
    "# Смотрим как скорость обучения по немного понижалась\n",
    "plot_learning_rate(lr_history5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "kTAlcNyLMlO4",
    "outputId": "fc85b11c-4cb8-471b-b8cc-6eaae3f91783"
   },
   "outputs": [],
   "source": [
    "plot([('Simple SGD', valid_loss_values), \n",
    "      ('momentum nesterov SGD', valid_loss_values2),\n",
    "      ('RMSprop', valid_loss_values3),\n",
    "      ('ADAM', valid_loss_values4),\n",
    "      ('ADAM_step', valid_loss_values5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6Wi1Va3vHYY"
   },
   "source": [
    "Попробуем ещё вариант!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmpv93IxvHYZ",
    "outputId": "a70a148b-309c-4389-910c-e9df4d5e2137"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "\n",
    "# Первая простенькая моделька \n",
    "model6 = MyModel()\n",
    "\n",
    "# инициализируем SGD optimizer\n",
    "adam = optim.Adam(model6.parameters(), lr=INIT_LR, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "# инициализируем \n",
    "scheduler = MultiStepLR(adam, milestones=[30,80], gamma=0.1)\n",
    "\n",
    "# запускаем процесс обучения\n",
    "train_loss_values6, train_accuracy_values6, valid_loss_values6, valid_accuracy6, lr_history6 = run_train(model6, optimizer=adam, \n",
    "                                                                                                        criterion=criterion, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "n43RxrQIOeoE",
    "outputId": "ab23e4b7-af64-4e17-c8d8-fdb24438555a"
   },
   "outputs": [],
   "source": [
    "# Смотрим как скорость обучения по немного понижалась\n",
    "plot_learning_rate(lr_history6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "50qD4pmKvHYZ",
    "outputId": "21b7f091-bd5f-421d-b1ed-fd063337eb2e"
   },
   "outputs": [],
   "source": [
    "plot([('Simple SGD', valid_loss_values), \n",
    "      ('momentum nesterov SGD', valid_loss_values2),\n",
    "      ('RMSprop', valid_loss_values3),\n",
    "      ('ADAM', valid_loss_values4),\n",
    "      ('ADAM_step', valid_loss_values5),\n",
    "      ('ADAM_step 2', valid_loss_values6)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SB5h35HRO5XI"
   },
   "source": [
    "Существует множество различных Scheduler`ов. Полный список можно найти на [странице](https://pytorch.org/docs/stable/optim.html) в разделе \"How to adjust learning rate\"\n",
    "\n",
    "Великолепное описание различных Scheduler`ов и как их применять можно найти по [ссылке](https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/lr_scheduling/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goMH1Np-vHYZ"
   },
   "source": [
    "## Авторские права и почиташки \n",
    "\n",
    "* Для создания тетрадки использовался [вот этот мануал](https://github.com/sukilau/Ziff-deep-learning/blob/master/3-CIFAR10-lrate/CIFAR10-lrate.ipynb), адаптированный под PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PNGBENzvHYZ"
   },
   "source": [
    "##   Поиграться при желании\n",
    "Пришло время заняться исследованиями! На лекции мы с вами обсудили, что сегодня люди ставят довольно большое число разных экспериментов с циклической скоростью обучения. Делают они это, чтобы как-то соскальзывать с сёдел и выбираться из локальных минимумов.  В этом задании вам надо будет немного поэкспериментировать с такими скоростями обучения. Предлагается поизучать [Scheduler`ы](https://pytorch.org/docs/stable/optim.html), реализованные в PyTorch и выбрать 2-3 для сравнения с рассмотренными вариантами на семинаре\n",
    "\n",
    "Вообще поощряются любые эксперименты. Не забывайте строить картинки. Можете как-то видоизменить архитектуру сетки. Например, добавить какие-то новые слои или сделать её глубже. Эксперименты можно оформлять прямо в этой тетрадке. Её же и присылайте.\n",
    "\n",
    "Если хочется вдохновения, [в этой статье](https://www.jeremyjordan.me/nn-learning-rate/) можно найти много разных вариантов пересчёта скорости обучения. Есть варианты с циклами и даже косинусами! Единственное, что код в статье написан на Keras, но это никак не мешает изучить суть алгоритмов. Еще одна полезная [ссылка](https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/lr_scheduling/).\n",
    "\n",
    "Плодотворных экспериментов :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBEKcQ1fvHYa"
   },
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_SGD_seminar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
